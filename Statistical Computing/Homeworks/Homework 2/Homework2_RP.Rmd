---
title: "Homework 2"
author: "Rodrigo Petricioli"
date: "9/8/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(135638)
```


## Question 1: Familiar with some discrete distributions. 

(a). 



```{r echo=T}
X <- rbinom(1000, 10, 0.7)
Y <- rbinom(1000, 10, 0.5)

hist(X, breaks = 0:10, col = 'blue4')
hist(Y, breaks = 0:10, col = 'red4')
```


(b).


```{r echo=T}
X <- rpois(1000,2)
Y <- rpois(1000,4)

hist(X, breaks = 0:15, col = 'blue4')

```
```{r echo=T}

hist(X, breaks = 0:15, col = 'blue4', add = F)
hist(Y, breaks = 0:15, col = 'red4', add = T)
```

## Question 2: Familiar with some continous distributions. 

(a). 


```{r echo=T}
X <- rgamma(100,1,1)
Y <- rgamma(100,2,1)
Z <- rgamma(100,1,2)

par(mfrow= c(1,3))

hist(X, col = 'blue4', freq = F)
curve(dgamma(x,1,1), add = T, col='red1')

hist(Y, col = 'blue4', freq = F, add = F)
curve(dgamma(x,2,1), add = T, col='red1')

hist(Z, col = 'blue4', freq = F, add = F)
curve(dgamma(x,1,2), add = T, col='red1')

par(mfrow= c(1,1))
```

(b). 


```{r echo=T}
curve(dbeta(x,3,3), col = 'blue4')
curve(dbeta(x,2,3), add = T, col='red1')
curve(dbeta(x,3,2), add = T, col='green1')
```

## Question 3: Verify some probability results using R. 

(a). 

```{r echo=T}
f1 <- function(x1, x2, x3, x4, x5){
  return (x1^2 + x2^2 + x3^2 + x4^2 + x5^2)
}

set.seed(135638)

X1 <- rnorm(1000,0,1)
X2 <- rnorm(1000,0,1)
X3 <- rnorm(1000,0,1)
X4 <- rnorm(1000,0,1)
X5 <- rnorm(1000,0,1)

Y <- f1(X1,X2,X3,X4,X5)

hist(Y, col = 'blue4', freq=F)
curve(dchisq(x,5), add=T, col='red')

```


(b). 


```{r echo=T}
f2 <- function(x1,x2,v){
  return (x1/sqrt(x2/v))
}

X <- rnorm(1000,0,1)
X2 <- rchisq(1000,4)

Y <- f2(X,X2,4)

hist(Y, col = 'blue4', freq=F)
curve(dt(x,4), col='red', add=T)

```

## Question 4: Verify the Law of Large Numbers using R. 


```{r echo=T}

set.seed(12345)
#(a). 
geom.exp <- function(p){
  return((1-p)/p)
}

geom.exp(0.6)

X1 <- rgeom(10,0.6)
X1_bar <- mean(X1)
X1_bar

X2 <- rgeom(100,0.6)
X2_bar <- mean(X2)

X3 <- rgeom(1000,0.6)
X3_bar <- mean(X3)

```
Difference between Sample Mean (n=10) and Expected Value: 

```{r echo=T}
X1_bar - geom.exp(0.6)
```

Difference between Sample Mean (n=100) and Expected Value: 

```{r echo=T}
X2_bar - geom.exp(0.6)
```

Difference between Sample Mean (n=1,000) and Expected Value: 

```{r echo=T}
X3_bar - geom.exp(0.6)
```

Difference between Bias(n=10) and Bias(n=1,000): 

```{r echo=T}
(X1_bar - geom.exp(0.6)) - (X3_bar - geom.exp(0.6))
```

As the sample grows larger, the bias grows smaller.




## Question 5: Verify the Central Limit Theorem using R. 


```{r echo=T}
set.seed(12345)

y1 <- rep(0,1000)
y2 <- rep(0,1000)
y3 <- rep(0,1000)

E1 <- matrix(1:(1000*5), ncol=5)
for (i in 1:1000){
  E1[i,] <- rexp(5,2)
  y1[i] <- mean(E1[i,])
}

E2 <- matrix(1:(1000*20), ncol=20)
for (i in 1:1000){
  E2[i,] <- rexp(20,2)
  y2[i] <- mean(E2[i,])
}

E3 <- matrix(1:(1000*50), ncol=50)
for (i in 1:1000){
  E3[i,] <- rexp(50,2)
  y3[i] <- mean(E3[i,])
}

par(mfrow=c(1,3))
hist(y1, col='blue4')
hist(y2, col='red4')
hist(y3, col='green4')

```

We observed that the means follow a Normal distribution, as the Central Limit Theorem tells us and as the sample size increases the histogram better approaches the Normal distribution. 






